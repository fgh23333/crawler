# Project Structure Documentation

## ğŸ“ Directory Structure

```
memcube-political/
â”œâ”€â”€ ğŸ“„ main.py                           # Main application entry point
â”œâ”€â”€ ğŸ“„ README.md                         # Project documentation
â”œâ”€â”€ ğŸ“„ requirements.txt                  # Python dependencies
â”œâ”€â”€ ğŸ“„ .gitignore                         # Git ignore configuration
â”‚
â”œâ”€â”€ ğŸ“ config/                           # Configuration files
â”‚   â”œâ”€â”€ config.yaml                     # Main system configuration
â”‚   â”œâ”€â”€ config.yaml.example             # Configuration template
â”‚   â””â”€â”€ api_keys.yaml                   # API keys (not in version control)
â”‚
â”œâ”€â”€ ğŸ“ src/                             # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                         # System controller and orchestration
â”‚   â”œâ”€â”€ concept_analyzer.py             # Concept analysis with LLMs
â”‚   â”œâ”€â”€ concept_extractor.py            # Concept extraction from text
â”‚   â”œâ”€â”€ concept_graph.py                # Graph construction and expansion
â”‚   â”œâ”€â”€ qa_generator.py                 # Q&A generation from concepts
â”‚   â”œâ”€â”€ evaluation.py                   # Quality assessment and metrics
â”‚   â”œâ”€â”€ api_client.py                   # LLM API client (OpenAI-compatible)
â”‚   â”œâ”€â”€ embedding_client.py             # Embedding client (Ollama)
â”‚   â”œâ”€â”€ graph_database_client.py        # Graph database abstraction
â”‚   â”œâ”€â”€ vector_database_client.py       # Vector database abstraction
â”‚   â”œâ”€â”€ knowledge_base_builder.py       # Knowledge base construction
â”‚   â””â”€â”€ prompt_templates.py             # LLM prompt templates
â”‚
â”œâ”€â”€ ğŸ“ scripts/                         # Utility and management scripts
â”‚   â”œâ”€â”€ check_env.py                    # Environment validation
â”‚   â”œâ”€â”€ quick_start.py                  # Quick start (memory mode)
â”‚   â”œâ”€â”€ quick_start_database.py        # Quick start (database mode)
â”‚   â”œâ”€â”€ test_api_simple.py              # Basic API connectivity test
â”‚   â”œâ”€â”€ test_api_config.py              # Detailed API configuration test
â”‚   â””â”€â”€ test_system.py                  # System functionality tests
â”‚
â”œâ”€â”€ ğŸ“ data/                            # Data storage
â”‚   â”œâ”€â”€ seed_concepts.txt               # Initial concept seeds (11,027)
â”‚   â”œâ”€â”€ seed_concepts.json              # Seeds in JSON format
â”‚   â”œâ”€â”€ transformed_political_data.json # Existing Q&A data (12,092)
â”‚   â”œâ”€â”€ political_theory_knowledge_base.yaml # Knowledge base
â”‚   â””â”€â”€ concept_graph/                  # Generated graph outputs
â”‚
â”œâ”€â”€ ğŸ“ results/                         # Processing results
â”‚   â”œâ”€â”€ political_theory_qa_dataset.json # Generated Q&A dataset
â”‚   â”œâ”€â”€ political_theory_qa_training.jsonl # Training format data
â”‚   â””â”€â”€ evaluation_reports/             # Quality assessment reports
â”‚
â”œâ”€â”€ ğŸ“ logs/                            # Application logs
â”œâ”€â”€ ğŸ“ docs/                            # Documentation
â””â”€â”€ ğŸ“ venv/                            # Python virtual environment
```

## ğŸ”§ Module Responsibilities

### Main Entry Points

#### `main.py` (Root Level)
- **Purpose**: Primary CLI interface and application launcher
- **Features**:
  - Command-line argument parsing
  - Environment validation
  - Stage-based execution control
  - Integration with both memory and database modes

#### `src/main.py`
- **Purpose**: System orchestration and pipeline control
- **Features**:
  - Pipeline stage management
  - Component initialization
  - Error handling and recovery
  - Progress tracking and logging

### Core Processing Modules

#### `concept_analyzer.py`
- **Purpose**: Deep semantic analysis of political theory concepts
- **Responsibilities**:
  - LLM-based concept analysis
  - Structured information extraction
  - Quality assurance of analysis results
  - Batch processing optimization

#### `concept_extractor.py`
- **Purpose**: Extract core concepts from analyzed text
- **Features**:
  - Named entity recognition
  - Concept normalization
  - Duplicate detection
  - Quality scoring

#### `concept_graph.py`
- **Purpose**: Knowledge graph construction and expansion
- **Algorithms**:
  - Iterative concept expansion
  - Similarity-based edge creation
  - Convergence detection
  - Graph quality assessment

#### `qa_generator.py`
- **Purpose**: Generate educational Q&A pairs from concepts
- **Capabilities**:
  - Single concept questions
  - Concept relationship questions
  - Multiple question types
  - Quality filtering and deduplication

#### `evaluation.py`
- **Purpose**: Comprehensive quality assessment
- **Metrics**:
  - Graph structure analysis
  - Semantic quality evaluation
  - Q&A content assessment
  - Performance benchmarking

### Database Abstraction Layer

#### `graph_database_client.py`
- **Purpose**: Graph database operations abstraction
- **Supported Databases**:
  - Neo4j (primary)
  - ArangoDB (alternative)
  - JanusGraph (alternative)
- **Features**:
  - Automatic fallback to memory mode
  - Connection pooling
  - Batch operations
  - Query optimization

#### `vector_database_client.py`
- **Purpose**: Vector database operations for similarity search
- **Supported Databases**:
  - Qdrant (primary)
  - ChromaDB (alternative)
  - FAISS (in-memory)
  - Milvus (distributed)
- **Features**:
  - Embedding storage and retrieval
  - Similarity search optimization
  - Index management
  - Automatic scaling

### API and Integration Layer

#### `api_client.py`
- **Purpose**: Unified LLM API client
- **Supported Providers**:
  - OpenAI (GPT-3.5, GPT-4, GPT-4o)
  - Google (Gemini models)
  - Anthropic (Claude)
  - Custom OpenAI-compatible endpoints
- **Features**:
  - Automatic retry logic
  - Rate limiting
  - Cost tracking
  - Response validation

#### `embedding_client.py`
- **Purpose**: Text embedding generation
- **Integration**:
  - Ollama (BGE-M3)
  - OpenAI embeddings
  - Local transformer models
- **Features**:
  - Batch processing
  - Caching
  - Dimension management
  - Performance optimization

## ğŸ”„ Data Flow Architecture

```
Seed Concepts Input
        â†“
   Concept Analysis
   (LLM Processing)
        â†“
   Concept Extraction
   (NLP Processing)
        â†“
   Graph Construction
   (Similarity Analysis)
        â†“
   Iterative Expansion
   (Quality Control)
        â†“
   Q&A Generation
   (Content Creation)
        â†“
   Quality Assessment
   (Evaluation)
        â†“
   Output Generation
   (Multiple Formats)
```

## ğŸ—„ï¸ Database Integration Strategy

### Dual-Mode Design

#### Memory Mode (Development/Testing)
- **Graph Storage**: NetworkX in-memory graphs
- **Vector Storage**: NumPy arrays
- **Advantages**: Fast, no external dependencies
- **Use Case**: Development, testing, small datasets

#### Database Mode (Production)
- **Graph Storage**: Neo4j/ArangoDB clusters
- **Vector Storage**: Qdrant/ChromaDB clusters
- **Advantages**: Scalable, persistent, concurrent access
- **Use Case**: Production, large datasets, multi-user

### Automatic Failover
- System detects database availability
- Graceful degradation to memory mode
- Seamless operation without user intervention
- Consistent API across modes

## âš™ï¸ Configuration System

### Hierarchical Configuration

1. **Default Values**: Built-in defaults
2. **Config Files**: `config.yaml` and `api_keys.yaml`
3. **Environment Variables**: Runtime overrides
4. **Command Line**: Immediate parameter changes

### Configuration Categories

#### API Configuration
- Model selection
- Rate limits
- Authentication
- Endpoint configuration

#### Processing Configuration
- Batch sizes
- Concurrency limits
- Quality thresholds
- Convergence parameters

#### Database Configuration
- Connection settings
- Performance tuning
- Backup strategies
- Security options

## ğŸ§ª Testing Architecture

### Test Categories

#### Unit Tests
- Individual module functionality
- Mock external dependencies
- Fast execution
- Comprehensive coverage

#### Integration Tests
- End-to-end workflows
- Database interactions
- API integrations
- Real data validation

#### Performance Tests
- Load testing
- Memory profiling
- Scalability validation
- Benchmarking

### Test Organization
```
tests/
â”œâ”€â”€ unit/                    # Unit tests
â”œâ”€â”€ integration/             # Integration tests
â”œâ”€â”€ performance/             # Performance tests
â””â”€â”€ fixtures/               # Test data
```

## ğŸ“Š Monitoring and Logging

### Logging Strategy

#### Structured Logging
- JSON format for machine parsing
- Consistent field naming
- Correlation IDs for request tracking
- Automatic log rotation

#### Log Levels
- **DEBUG**: Detailed debugging information
- **INFO**: General operational information
- **WARNING**: Warning conditions
- **ERROR**: Error conditions
- **CRITICAL**: Critical system failures

### Monitoring Metrics

#### System Metrics
- CPU and memory usage
- API request rates
- Database performance
- Processing throughput

#### Business Metrics
- Concept discovery rate
- Q&A generation quality
- User engagement (if applicable)
- System uptime

## ğŸ”’ Security Considerations

### API Key Management
- Environment-based configuration
- Secure storage practices
- Rotation strategies
- Access logging

### Data Protection
- Input validation
- Output sanitization
- Database encryption
- Access controls

### System Hardening
- Dependency scanning
- Security patches
- Network security
- Audit logging

## ğŸš€ Deployment Architecture

### Development Environment
- Local development setup
- Docker compose for services
- Hot reloading
- Debug configurations

### Production Environment
- Container orchestration
- Load balancing
- Auto-scaling
- Monitoring integration

### CI/CD Pipeline
- Automated testing
- Security scanning
- Deployment automation
- Rollback strategies

---

This structure provides a robust foundation for scalable AI-powered knowledge graph construction while maintaining flexibility for different use cases and deployment scenarios.