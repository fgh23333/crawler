"""
MemCube æ”¿æ²»ç†è®ºæ¦‚å¿µå›¾æ‰©å¢ç³»ç»Ÿ - ä¸»ç¨‹åºå…¥å£
"""

import argparse
import logging
import sys
import yaml
from pathlib import Path
from loguru import logger

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from concept_analyzer import analyze_concepts_from_file
from concept_extractor import extract_concepts_from_analysis
from concept_graph import expand_concept_graph
from qa_generator import generate_political_theory_qa

def setup_logging(config):
    """è®¾ç½®æ—¥å¿—"""
    from loguru import logger

    # ç§»é™¤é»˜è®¤å¤„ç†å™¨
    logger.remove()

    # æ·»åŠ æ§åˆ¶å°è¾“å‡º
    logger.add(
        sys.stdout,
        format=config['logging']['format'],
        level=config['logging']['level'],
        colorize=True
    )

    # æ·»åŠ æ–‡ä»¶è¾“å‡º
    logs_dir = Path(config['paths']['logs_dir'])
    logs_dir.mkdir(parents=True, exist_ok=True)

    logger.add(
        logs_dir / "memcube_{time:YYYY-MM-DD}.log",
        format=config['logging']['format'],
        level=config['logging']['level'],
        rotation=config['logging']['rotation'],
        retention=config['logging']['retention'],
        encoding='utf-8'
    )

def validate_api_config():
    """éªŒè¯APIé…ç½®"""
    api_config_file = Path("config/api_keys.yaml")
    if not api_config_file.exists():
        logger.error("APIé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        logger.info("è¯·å¤åˆ¶ config/api_keys.yaml.example ä¸º config/api_keys.yaml")
        logger.info("ç„¶åå¡«å…¥ä½ çš„OpenAI APIå¯†é’¥")
        return False

    # æ£€æŸ¥æ˜¯å¦ä¸ºç¤ºä¾‹æ–‡ä»¶
    with open(api_config_file, 'r', encoding='utf-8') as f:
        content = f.read()
        if 'your-openai-api-key-here' in content:
            logger.error("è¯·å…ˆé…ç½®APIå¯†é’¥ï¼")
            logger.info("ç¼–è¾‘ config/api_keys.yaml æ–‡ä»¶ï¼Œå¡«å…¥çœŸå®çš„APIå¯†é’¥")
            return False

    return True

def run_stage_concept_analysis(config):
    """è¿è¡Œç¬¬ä¸€é˜¶æ®µï¼šæ¦‚å¿µåˆ†æ"""
    logger.info("=" * 60)
    logger.info("å¼€å§‹ç¬¬ä¸€é˜¶æ®µï¼šç§å­æ¦‚å¿µæ€è€ƒåˆ†æ")
    logger.info("=" * 60)

    seed_concepts_file = config['paths']['seed_concepts']
    if not Path(seed_concepts_file).exists():
        logger.error(f"ç§å­æ¦‚å¿µæ–‡ä»¶ä¸å­˜åœ¨: {seed_concepts_file}")
        return None

    # è¿è¡Œæ¦‚å¿µåˆ†æ
    analysis_file = analyze_concepts_from_file(
        concepts_file=seed_concepts_file,
        config_file="config/config.yaml",
        batch_size=config['concept_expansion']['batch_size'],
        max_workers=config['concept_expansion']['max_workers']
    )

    logger.success(f"æ¦‚å¿µåˆ†æå®Œæˆï¼Œç»“æœæ–‡ä»¶: {analysis_file}")
    return analysis_file

def run_stage_concept_extraction(config):
    """è¿è¡Œç¬¬ä¸€é˜¶æ®µï¼šæ¦‚å¿µæå–"""
    logger.info("=" * 60)
    logger.info("å¼€å§‹ç¬¬ä¸€é˜¶æ®µï¼šä»æ€è€ƒåˆ†æä¸­æå–æ¦‚å¿µ")
    logger.info("=" * 60)

    # æŸ¥æ‰¾æœ€æ–°çš„åˆ†æç»“æœæ–‡ä»¶
    results_dir = Path(config['paths']['results_dir']) / "concept_analysis"
    analysis_files = list(results_dir.glob("concept_analysis_results.json"))

    if not analysis_files:
        logger.error("æœªæ‰¾åˆ°æ¦‚å¿µåˆ†æç»“æœæ–‡ä»¶ï¼")
        logger.info("è¯·å…ˆè¿è¡Œ --stage concept-analysis")
        return None

    analysis_file = max(analysis_files, key=lambda x: x.stat().st_mtime)
    logger.info(f"ä½¿ç”¨åˆ†æç»“æœæ–‡ä»¶: {analysis_file}")

    # è¿è¡Œæ¦‚å¿µæå–
    concepts_file = extract_concepts_from_analysis(
        analysis_file=str(analysis_file),
        config_file="config/config.yaml",
        batch_size=config['concept_expansion']['batch_size'],
        max_workers=config['concept_expansion']['max_workers']
    )

    logger.success(f"æ¦‚å¿µæå–å®Œæˆï¼Œç»“æœæ–‡ä»¶: {concepts_file}")
    return concepts_file

def run_stage_concept_expansion(config):
    """è¿è¡Œç¬¬äºŒé˜¶æ®µï¼šæ¦‚å¿µå›¾æ‰©å¢"""
    logger.info("=" * 60)
    logger.info("å¼€å§‹ç¬¬äºŒé˜¶æ®µï¼šæ¦‚å¿µå›¾è¿­ä»£æ‰©å¢")
    logger.info("=" * 60)

    seed_concepts_file = config['paths']['seed_concepts']
    if not Path(seed_concepts_file).exists():
        logger.error(f"ç§å­æ¦‚å¿µæ–‡ä»¶ä¸å­˜åœ¨: {seed_concepts_file}")
        return None

    # è¿è¡Œæ¦‚å¿µå›¾æ‰©å¢
    graph_dir = expand_concept_graph(
        seed_concepts_file=seed_concepts_file,
        config_file="config/config.yaml"
    )

    logger.success(f"æ¦‚å¿µå›¾æ‰©å¢å®Œæˆï¼Œç»“æœç›®å½•: {graph_dir}")

    # è¿”å›æ¦‚å¿µå›¾æ–‡ä»¶è·¯å¾„
    graph_file = Path(graph_dir) / "final_concept_graph.json"
    return str(graph_file) if graph_file.exists() else None

def run_stage_qa_generation(config, graph_file=None):
    """è¿è¡Œç¬¬ä¸‰é˜¶æ®µï¼šQAç”Ÿæˆ"""
    logger.info("=" * 60)
    logger.info("å¼€å§‹ç¬¬ä¸‰é˜¶æ®µï¼šQAçŸ¥è¯†ç”Ÿæˆ")
    logger.info("=" * 60)

    if not graph_file:
        # æŸ¥æ‰¾æœ€æ–°çš„æ¦‚å¿µå›¾æ–‡ä»¶
        concept_graph_dir = Path(config['paths']['concept_graph_dir'])
        graph_files = list(concept_graph_dir.glob("final_concept_graph.json"))

        if not graph_files:
            logger.error("æœªæ‰¾åˆ°æ¦‚å¿µå›¾æ–‡ä»¶ï¼")
            logger.info("è¯·å…ˆè¿è¡Œ --stage concept-expansion")
            return None

        graph_file = max(graph_files, key=lambda x: x.stat().st_mtime)
        logger.info(f"ä½¿ç”¨æ¦‚å¿µå›¾æ–‡ä»¶: {graph_file}")

    # è¿è¡ŒQAç”Ÿæˆ
    result_summary = generate_political_theory_qa(
        concept_graph_file=graph_file,
        config_file="config/config.yaml"
    )

    logger.success("QAç”Ÿæˆå®Œæˆï¼")
    logger.info(f"ç”Ÿæˆç»Ÿè®¡:")
    logger.info(f"  - æ€»QAå¯¹æ•°: {result_summary['after_filtering']}")
    logger.info(f"  - å•æ¦‚å¿µQA: {result_summary['generated_single_concept_qa']}")
    logger.info(f"  - æ¦‚å¿µå¯¹QA: {result_summary['generated_concept_pair_qa']}")

    return result_summary

def run_full_pipeline(config):
    """è¿è¡Œå®Œæ•´æµç¨‹"""
    logger.info("=" * 80)
    logger.info("å¼€å§‹ MemCube æ”¿æ²»ç†è®ºæ¦‚å¿µå›¾æ‰©å¢å®Œæ•´æµç¨‹")
    logger.info("=" * 80)

    # éªŒè¯APIé…ç½®
    if not validate_api_config():
        return

    # é˜¶æ®µ1ï¼šæ¦‚å¿µå›¾æ‰©å¢ï¼ˆå¦‚æœç§å­æ¦‚å¿µå·²ç»å‡†å¤‡å¥½ï¼Œå¯ä»¥ç›´æ¥è·³åˆ°æ¦‚å¿µæ‰©å¢ï¼‰
    logger.info("ğŸš€ é˜¶æ®µ1ï¼šæ¦‚å¿µå›¾è¿­ä»£æ‰©å¢")
    graph_file = run_stage_concept_expansion(config)

    if not graph_file:
        logger.error("æ¦‚å¿µå›¾æ‰©å¢å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢")
        return

    # é˜¶æ®µ2ï¼šQAç”Ÿæˆ
    logger.info("ğŸš€ é˜¶æ®µ2ï¼šQAçŸ¥è¯†ç”Ÿæˆ")
    qa_result = run_stage_qa_generation(config, graph_file)

    if not qa_result:
        logger.error("QAç”Ÿæˆå¤±è´¥")
        return

    # å®Œæˆæ€»ç»“
    logger.info("=" * 80)
    logger.success("ğŸ‰ MemCube å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæˆï¼")
    logger.info("=" * 80)
    logger.info("ç”Ÿæˆçš„æ–‡ä»¶:")
    for output_file in qa_result.get('output_files', []):
        logger.info(f"  - {output_file}")

    logger.info("\nä¸‹ä¸€æ­¥:")
    logger.info("1. æ£€æŸ¥ç”Ÿæˆçš„QAæ•°æ®è´¨é‡")
    logger.info("2. å¯ä»¥å°†æ•°æ®å¯¼å…¥å›¾æ•°æ®åº“è¿›è¡Œç®¡ç†")
    logger.info("3. åŸºäºç”Ÿæˆçš„çŸ¥è¯†æ„å»ºåº”ç”¨ç³»ç»Ÿ")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="MemCube æ”¿æ²»ç†è®ºæ¦‚å¿µå›¾æ‰©å¢ç³»ç»Ÿ")

    parser.add_argument(
        "--stage",
        choices=[
            "concept-analysis",     # æ¦‚å¿µæ€è€ƒåˆ†æ
            "concept-extraction",   # æ¦‚å¿µæå–
            "concept-expansion",     # æ¦‚å¿µå›¾æ‰©å¢
            "qa-generation",         # QAç”Ÿæˆ
            "all"                   # å®Œæ•´æµç¨‹
        ],
        default="all",
        help="é€‰æ‹©è¦è¿è¡Œçš„é˜¶æ®µ"
    )

    parser.add_argument(
        "--config",
        default="config/config.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    try:
        with open(args.config, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
    except Exception as e:
        logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return

    # è®¾ç½®æ—¥å¿—
    setup_logging(config)

    logger.info("MemCube æ”¿æ²»ç†è®ºæ¦‚å¿µå›¾æ‰©å¢ç³»ç»Ÿå¯åŠ¨")
    logger.info(f"è¿è¡Œé˜¶æ®µ: {args.stage}")
    logger.info(f"é…ç½®æ–‡ä»¶: {args.config}")

    # éªŒè¯APIé…ç½®
    if args.stage != "concept-analysis":  # concept-analysisé˜¶æ®µå¯èƒ½ä¸éœ€è¦API
        if not validate_api_config():
            return

    # æ ¹æ®é€‰æ‹©çš„é˜¶æ®µè¿è¡Œ
    try:
        if args.stage == "concept-analysis":
            run_stage_concept_analysis(config)
        elif args.stage == "concept-extraction":
            run_stage_concept_extraction(config)
        elif args.stage == "concept-expansion":
            run_stage_concept_expansion(config)
        elif args.stage == "qa-generation":
            run_stage_qa_generation(config)
        elif args.stage == "all":
            run_full_pipeline(config)

    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
    except Exception as e:
        logger.error(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")

    logger.info("ç¨‹åºæ‰§è¡Œç»“æŸ")

if __name__ == "__main__":
    main()